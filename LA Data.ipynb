{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Read the data into a panda dataframe\n",
    "\n",
    "Build training data using the not null data and a prediction set using the null data.\n",
    "\n",
    "Then split up the training data into a training set and a cross validation set by randomly splitting items up by their program priority code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('la_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data = df[df[\"Expense_Type\"].notnull()]\n",
    "full_data = full_data.dropna(how='any')\n",
    "empty_data = df[False == df[\"Expense_Type\"].notnull()]\n",
    "\n",
    "\n",
    "single_empty = empty_data[empty_data[\"Program_Name\"].notnull()]\n",
    "all_empty = empty_data[False == empty_data[\"Program_Name\"].notnull()]\n",
    "\n",
    "priorities = full_data[\"Program_Priority\"].unique()\n",
    "programs = full_data[\"Program_Name\"].unique()\n",
    "expenses = full_data[\"Expense_Type\"].unique()\n",
    "departments = full_data[\"Dept_Code\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Strings to Ints\n",
    "\n",
    "Before trying to run word2vec, try just running random forest on data giving each string a unique int id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def string_col_to_int(column, keys):\n",
    "    \n",
    "    for i, key in enumerate(keys):\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            index = full_data[column] == key\n",
    "        except:\n",
    "            return\n",
    "        \n",
    "        full_data.loc[index, column] = i\n",
    "        \n",
    "        \n",
    "string_col_to_int(\"Program_Priority\", priorities)\n",
    "string_col_to_int(\"Expense_Type\", expenses)\n",
    "string_col_to_int(\"Program_Name\", programs)\n",
    "string_col_to_int(\"Dept_Code\", departments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than Dept_Code and Program name, there don't appear to be any great correlations with Expense type. I'm not too optimistic about this approach, but let's see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dept_Code</th>\n",
       "      <th>Program_Name</th>\n",
       "      <th>Program_Priority</th>\n",
       "      <th>Appropriation</th>\n",
       "      <th>Fiscal_Year</th>\n",
       "      <th>Expense_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dept_Code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543935</td>\n",
       "      <td>-0.179315</td>\n",
       "      <td>0.028250</td>\n",
       "      <td>0.135587</td>\n",
       "      <td>0.292920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Program_Name</th>\n",
       "      <td>0.543935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.226268</td>\n",
       "      <td>0.054728</td>\n",
       "      <td>0.222927</td>\n",
       "      <td>0.353792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Program_Priority</th>\n",
       "      <td>-0.179315</td>\n",
       "      <td>-0.226268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>-0.284997</td>\n",
       "      <td>-0.048432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Appropriation</th>\n",
       "      <td>0.028250</td>\n",
       "      <td>0.054728</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.094468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiscal_Year</th>\n",
       "      <td>0.135587</td>\n",
       "      <td>0.222927</td>\n",
       "      <td>-0.284997</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expense_Type</th>\n",
       "      <td>0.292920</td>\n",
       "      <td>0.353792</td>\n",
       "      <td>-0.048432</td>\n",
       "      <td>0.094468</td>\n",
       "      <td>0.146356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Dept_Code  Program_Name  Program_Priority  Appropriation  \\\n",
       "Dept_Code          1.000000      0.543935         -0.179315       0.028250   \n",
       "Program_Name       0.543935      1.000000         -0.226268       0.054728   \n",
       "Program_Priority  -0.179315     -0.226268          1.000000       0.062527   \n",
       "Appropriation      0.028250      0.054728          0.062527       1.000000   \n",
       "Fiscal_Year        0.135587      0.222927         -0.284997       0.017380   \n",
       "Expense_Type       0.292920      0.353792         -0.048432       0.094468   \n",
       "\n",
       "                  Fiscal_Year  Expense_Type  \n",
       "Dept_Code            0.135587      0.292920  \n",
       "Program_Name         0.222927      0.353792  \n",
       "Program_Priority    -0.284997     -0.048432  \n",
       "Appropriation        0.017380      0.094468  \n",
       "Fiscal_Year          1.000000      0.146356  \n",
       "Expense_Type         0.146356      1.000000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['Dept_Code']\n",
      " Acc:  0.571494893222\n",
      "Keys:  ['Appropriation']\n",
      " Acc:  0.644586894587\n",
      "Keys:  ['Program_Name']\n",
      " Acc:  0.588126588127\n",
      "Keys:  ['Program_Priority']\n",
      " Acc:  0.483540076336\n",
      "Keys:  ['Dept_Code', 'Appropriation']\n",
      " Acc:  0.745346062053\n",
      "Keys:  ['Program_Name', 'Program_Priority']\n",
      " Acc:  0.574568659891\n"
     ]
    }
   ],
   "source": [
    "guaranteed = [\"Dept_Code\", \"Appropriation\"]\n",
    "not_guaranteed = [\"Program_Name\", \"Program_Priority\"]\n",
    "all_keys = guaranteed + not_guaranteed\n",
    "\n",
    "\n",
    "def train_and_score_rfc(data, train_keys,  iterations=1):\n",
    "    \n",
    "    train, cv = random_cv_split(full_data)\n",
    "    \n",
    "    rfc_low = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        rfc_low.fit(train[train_keys], train[\"Expense_Type\"])\n",
    "        score = rfc_low.score(cv[train_keys], cv[\"Expense_Type\"])\n",
    "        print(\"Keys: \", train_keys)\n",
    "        print(\" Acc: \", score )\n",
    "\n",
    "    \n",
    "    return rfc_low\n",
    "    \n",
    "rfc = train_and_score_rfc(full_data, [\"Dept_Code\"])\n",
    "rfc = train_and_score_rfc(full_data, [\"Appropriation\"])\n",
    "rfc = train_and_score_rfc(full_data, [\"Program_Name\"])\n",
    "rfc = train_and_score_rfc(full_data, [\"Program_Priority\"])\n",
    "rfc = train_and_score_rfc(full_data, guaranteed)\n",
    "rfc = train_and_score_rfc(full_data, not_guaranteed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So interesting results here: It seems that the best individual indicator is simply Appropriation which makes sense. Then is program name and not far behind Dept code. Last is program priority which makes sense because that was a complex description. So this is kind of good news because for about 200 rows, the only info we have is the dept code and appropriation, so for those rows which we can't run embeddings on, we can still get descent results, given the ~75% accuracy of the only guaranteed keys\n",
    "\n",
    "Now I'm going to try a few combinations just to get a better feel for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['Program_Name', 'Appropriation']\n",
      " Acc:  0.778542606219\n",
      "Keys:  ['Program_Priority', 'Appropriation']\n",
      " Acc:  0.612324672338\n",
      "Keys:  ['Program_Name', 'Appropriation', 'Dept_Code']\n",
      " Acc:  0.783149171271\n",
      "Keys:  ['Dept_Code', 'Appropriation', 'Program_Name', 'Program_Priority']\n",
      " Acc:  0.751053864169\n"
     ]
    }
   ],
   "source": [
    "rfc = train_and_score_rfc(full_data, [\"Program_Name\", \"Appropriation\"])\n",
    "rfc = train_and_score_rfc(full_data, [\"Program_Priority\", \"Appropriation\"])\n",
    "rfc = train_and_score_rfc(full_data, [\"Program_Name\", \"Appropriation\", \"Dept_Code\"] )\n",
    "rfc = train_and_score_rfc(full_data, all_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best combination is essentially all the keys minus program priority which is something to keep in mind for later. I'm interested to see how the random forest results differ with embedding as opposed to unique values.\n",
    "\n",
    "Random Forest was my first instinct to try on this data but I'm gonna try an SVM just in case it is closer to being linearly separablee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC guaranteed data Score:  0.702265372168\n",
      "SVC not guaranteed data Score:  0.701571890892\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def train_and_score_svc(data, iterations=1):\n",
    "    \n",
    "    train, cv = random_cv_split(full_data)\n",
    "    \n",
    "    svc_g = svm.SVC()\n",
    "    svc_ng = svm.SVC()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "\n",
    "        svc_g.fit(train[guaranteed], train[\"Expense_Type\"])\n",
    "        score = svc_g.score(cv[guaranteed], cv[\"Expense_Type\"])\n",
    "        print(\"SVC guaranteed data Score: \", score)\n",
    "\n",
    "\n",
    "        svc_ng.fit(train[guaranteed+not_guaranteed], train[\"Expense_Type\"])\n",
    "        score = svc_ng.score(cv[guaranteed+not_guaranteed], cv[\"Expense_Type\"])\n",
    "        print(\"SVC not guaranteed data Score: \", score)\n",
    "    \n",
    "    \n",
    "    return svc_g, svc_ng\n",
    "\n",
    "svc_g, svc_ng = train_and_score_svc(full_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good results as Random Forest, but it might scale better. With a smaller dataset I might use svm, but becasue we have around 80% of the data already filled and 20% not filled, I'm leaning towards the random forest\n",
    "\n",
    "Also, SVM performs worse given the program name and ID, because it probably just adds unneccessary complexity towards the fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
