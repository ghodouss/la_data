{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils import random_cv_split, int_col_to_string, string_col_to_int, load_gensim_model, encode_column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Read the data into a panda dataframe\n",
    "\n",
    "Build training data using the not null data and a prediction set using the null data.\n",
    "\n",
    "Then split up the training data into a training set and a cross validation set by randomly splitting items up by their program priority code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/LA_Budget_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dept_Code has nulls:  True\n",
      "Department_Name has nulls:  False\n",
      "SubDept_Code has nulls:  False\n",
      "SubDepartment_Name has nulls:  False\n",
      "Prog_Code has nulls:  True\n",
      "Program_Name has nulls:  True\n",
      "Program_Priority has nulls:  True\n",
      "Source_Fund_Code has nulls:  True\n",
      "Source_Fund_Name has nulls:  True\n",
      "Account_Code has nulls:  True\n",
      "Account_Name has nulls:  True\n",
      "Appropriation has nulls:  False\n",
      "Fiscal_Year has nulls:  False\n",
      "Expense_Type has nulls:  True\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    \n",
    "    nulls = df[column].isnull().any()\n",
    "    print(column, \"has nulls: \", nulls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoders = {}\n",
    "\n",
    "\n",
    "decoders[\"Department_Name\"] = encode_column(df, \"Department_Name\")\n",
    "decoders[\"SubDepartment_Name\"] = encode_column(df, \"SubDepartment_Name\")\n",
    "\n",
    "full_data = df[df[\"Expense_Type\"].notnull()]\n",
    "full_data = full_data.dropna(how='any')\n",
    "\n",
    "encode_column(full_data, \"Expense_Type\")\n",
    "encode_column(full_data, \"Program_Priority\")\n",
    "encode_column(full_data, \"Program_Name\")\n",
    "\n",
    "\n",
    "\n",
    "empty_data = df[False == df[\"Expense_Type\"].notnull()]\n",
    "\n",
    "\n",
    "single_empty = empty_data[empty_data[\"Program_Name\"].notnull()]\n",
    "all_empty = empty_data[False == empty_data[\"Program_Name\"].notnull()]\n",
    "\n",
    "priorities = full_data[\"Program_Priority\"].unique()\n",
    "programs = full_data[\"Program_Name\"].unique()\n",
    "expenses = full_data[\"Expense_Type\"].unique()\n",
    "departments = full_data[\"Dept_Code\"].unique()\n",
    "\n",
    "guaranteed = [\"Encoded_SubDepartment_Name\", \"Encoded_Department_Name\", \"Appropriation\"]\n",
    "not_guaranteed = [\"Encoded_Program_Name\", \"Encoded_Program_Priority\"]\n",
    "\n",
    "all_keys = guaranteed + not_guaranteed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Strings to Ints\n",
    "\n",
    "Before trying to run word2vec, try just running random forest on data giving each string a unique int id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look For Easy Correlations\n",
    "\n",
    "Other than Dept_Code and Program name, there don't appear to be any great correlations with Expense type. I'm not too optimistic about this approach, but let's see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appropriation</th>\n",
       "      <th>Fiscal_Year</th>\n",
       "      <th>Encoded_Department_Name</th>\n",
       "      <th>Encoded_SubDepartment_Name</th>\n",
       "      <th>Encoded_Expense_Type</th>\n",
       "      <th>Encoded_Program_Priority</th>\n",
       "      <th>Encoded_Program_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Appropriation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.022168</td>\n",
       "      <td>0.041060</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>-0.004502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiscal_Year</th>\n",
       "      <td>0.017380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.138887</td>\n",
       "      <td>0.032914</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>-0.292256</td>\n",
       "      <td>0.038540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encoded_Department_Name</th>\n",
       "      <td>0.022168</td>\n",
       "      <td>-0.138887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.530920</td>\n",
       "      <td>0.040165</td>\n",
       "      <td>-0.125534</td>\n",
       "      <td>0.138764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encoded_SubDepartment_Name</th>\n",
       "      <td>0.041060</td>\n",
       "      <td>0.032914</td>\n",
       "      <td>0.530920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075124</td>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.071454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encoded_Expense_Type</th>\n",
       "      <td>0.036633</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>0.040165</td>\n",
       "      <td>0.075124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054820</td>\n",
       "      <td>-0.025987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encoded_Program_Priority</th>\n",
       "      <td>0.008716</td>\n",
       "      <td>-0.292256</td>\n",
       "      <td>-0.125534</td>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.054820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encoded_Program_Name</th>\n",
       "      <td>-0.004502</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>0.138764</td>\n",
       "      <td>0.071454</td>\n",
       "      <td>-0.025987</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Appropriation  Fiscal_Year  \\\n",
       "Appropriation                    1.000000     0.017380   \n",
       "Fiscal_Year                      0.017380     1.000000   \n",
       "Encoded_Department_Name          0.022168    -0.138887   \n",
       "Encoded_SubDepartment_Name       0.041060     0.032914   \n",
       "Encoded_Expense_Type             0.036633    -0.092946   \n",
       "Encoded_Program_Priority         0.008716    -0.292256   \n",
       "Encoded_Program_Name            -0.004502     0.038540   \n",
       "\n",
       "                            Encoded_Department_Name  \\\n",
       "Appropriation                              0.022168   \n",
       "Fiscal_Year                               -0.138887   \n",
       "Encoded_Department_Name                    1.000000   \n",
       "Encoded_SubDepartment_Name                 0.530920   \n",
       "Encoded_Expense_Type                       0.040165   \n",
       "Encoded_Program_Priority                  -0.125534   \n",
       "Encoded_Program_Name                       0.138764   \n",
       "\n",
       "                            Encoded_SubDepartment_Name  Encoded_Expense_Type  \\\n",
       "Appropriation                                 0.041060              0.036633   \n",
       "Fiscal_Year                                   0.032914             -0.092946   \n",
       "Encoded_Department_Name                       0.530920              0.040165   \n",
       "Encoded_SubDepartment_Name                    1.000000              0.075124   \n",
       "Encoded_Expense_Type                          0.075124              1.000000   \n",
       "Encoded_Program_Priority                      0.018711              0.054820   \n",
       "Encoded_Program_Name                          0.071454             -0.025987   \n",
       "\n",
       "                            Encoded_Program_Priority  Encoded_Program_Name  \n",
       "Appropriation                               0.008716             -0.004502  \n",
       "Fiscal_Year                                -0.292256              0.038540  \n",
       "Encoded_Department_Name                    -0.125534              0.138764  \n",
       "Encoded_SubDepartment_Name                  0.018711              0.071454  \n",
       "Encoded_Expense_Type                        0.054820             -0.025987  \n",
       "Encoded_Program_Priority                    1.000000              0.011057  \n",
       "Encoded_Program_Name                        0.011057              1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Random Forest\n",
    "\n",
    "Try running data through a random forest classifier with various combinations to see how they work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['Encoded_SubDepartment_Name', 'Encoded_Department_Name', 'Appropriation']\n",
      " Acc:  0.7289198606271777\n",
      "Keys:  ['Encoded_Program_Name', 'Encoded_Program_Priority']\n",
      " Acc:  0.5756380510440835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#string_col_to_int(\"Dept_Code\", departments, full_data)\n",
    "\n",
    "def train_and_score_rfc(data, train_keys,  iterations=1):\n",
    "    \n",
    "    train, cv = random_cv_split(full_data)\n",
    "    \n",
    "    rfc_low = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        rfc_low.fit(train[train_keys], train[\"Expense_Type\"])\n",
    "        score = rfc_low.score(cv[train_keys], cv[\"Expense_Type\"])\n",
    "        print(\"Keys: \", train_keys)\n",
    "        print(\" Acc: \", score )\n",
    "\n",
    "    \n",
    "    return rfc_low\n",
    "\n",
    "rfc_g = train_and_score_rfc(full_data, guaranteed)\n",
    "rfc_ng = train_and_score_rfc(full_data, not_guaranteed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So interesting results here: It seems that the best individual indicator is simply Appropriation which makes sense. Then is program name and not far behind Dept code. Last is program priority which makes sense because that was a complex description. So this is kind of good news because for about 200 rows, the only info we have is the dept code and appropriation, so for those rows which we can't run embeddings on, we can still get descent results, given the ~75% accuracy of the only guaranteed keys\n",
    "\n",
    "Now I'm going to try a few combinations just to get a better feel for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['Encoded_Program_Name', 'Appropriation']\n",
      " Acc:  0.762163438828531\n",
      "Keys:  ['Encoded_Program_Priority', 'Appropriation']\n",
      " Acc:  0.6051601013591339\n",
      "Keys:  ['Encoded_Program_Name', 'Appropriation', 'Encoded_Department_Name']\n",
      " Acc:  0.7748703441772749\n",
      "Keys:  ['Encoded_Program_Name', 'Appropriation', 'Encoded_SubDepartment_Name', 'Encoded_Department_Name']\n",
      " Acc:  0.7843409775306927\n",
      "Keys:  ['Encoded_SubDepartment_Name', 'Encoded_Department_Name', 'Appropriation', 'Encoded_Program_Name', 'Encoded_Program_Priority']\n",
      " Acc:  0.7472025576615665\n"
     ]
    }
   ],
   "source": [
    "rfc = train_and_score_rfc(full_data, [\"Encoded_Program_Name\", \"Appropriation\"])\n",
    "rfc = train_and_score_rfc(full_data, [\"Encoded_Program_Priority\", \"Appropriation\"])\n",
    "rfc = train_and_score_rfc(full_data, [\"Encoded_Program_Name\", \"Appropriation\", \"Encoded_Department_Name\"] )\n",
    "rfc = train_and_score_rfc(full_data, [\"Encoded_Program_Name\", \"Appropriation\", \n",
    "                                      \"Encoded_SubDepartment_Name\", \"Encoded_Department_Name\" ] )\n",
    "rfc_all = train_and_score_rfc(full_data, all_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best combination is essentially all the keys minus program priority which is something to keep in mind for later. I'm interested to see how the random forest results differ with embedding as opposed to unique values.\n",
    "\n",
    "Random Forest was my first instinct to try on this data but I'm gonna try an SVM just in case it is closer to being linearly separablee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the Decision Breakdown\n",
    "\n",
    "I'm going to plot the decision breakdown of the guaranteed and not guaranteed rfc to see if they lend any insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAEWCAYAAADsCgQrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncEhkMcPPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf0e9bafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEWCAYAAACpPdRYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf0e904a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAEWCAYAAADsCgQrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf0ea32e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_rfc_weights(forest, columns, fig_num=1):\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "    columns=np.array(columns)\n",
    "\n",
    "    indices = np.argsort(importances)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), columns[indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "\n",
    "    return\n",
    "\n",
    "plot_rfc_weights(rfc_g, guaranteed, 1)\n",
    "plot_rfc_weights(rfc_ng, not_guaranteed, 2)\n",
    "plot_rfc_weights(rfc_all, all_keys, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TakeAway\n",
    "\n",
    "So, unsurprisingly, the Appropriation ammmount is by far the most considered part of the data, followed by the program name. I'm gonna try to do some more work with the program name to extract more information from it later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC guaranteed data Score:  0.6745699674569967\n",
      "SVC not guaranteed data Score:  0.6706183170618317\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def train_and_score_svc(data, iterations=1):\n",
    "    \n",
    "    train, cv = random_cv_split(full_data)\n",
    "    \n",
    "    svc_g = svm.SVC()\n",
    "    svc_ng = svm.SVC()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "\n",
    "        svc_g.fit(train[guaranteed], train[\"Expense_Type\"])\n",
    "        score = svc_g.score(cv[guaranteed], cv[\"Expense_Type\"])\n",
    "        print(\"SVC guaranteed data Score: \", score)\n",
    "\n",
    "\n",
    "        svc_ng.fit(train[guaranteed+not_guaranteed], train[\"Expense_Type\"])\n",
    "        score = svc_ng.score(cv[guaranteed+not_guaranteed], cv[\"Expense_Type\"])\n",
    "        print(\"SVC not guaranteed data Score: \", score)\n",
    "    \n",
    "    \n",
    "    return svc_g, svc_ng\n",
    "\n",
    "svc_g, svc_ng = train_and_score_svc(full_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good results as Random Forest, but it might scale better. With a smaller dataset I might use svm, but becasue we have around 80% of the data already filled and 20% not filled, I'm leaning towards the random forest\n",
    "\n",
    "Also, SVM performs worse given the program name and ID, because it probably just adds unneccessary complexity towards the fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "A major idea in NLP is the idea that word can be encoded into a vector space. Something interesting about this vector space, however, is that the difference in values (i.e. distance) between similar words and phrases will be smaller than the difference in values between dissimilar words. I'm going to try to leverage these encodings to see if there is a greater theme in either program priority or program names and the expense types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import logging, urllib.request, zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Gensim\n",
    "\n",
    "We have to first train Gensim on data in order to load the word2vec of our data. These are some functions to read the zipfile, extract the zipfile, train gensim, and finally save the model under 'mymodel' so we don't have to retrain every time\n",
    "\n",
    "I did packaged all this into a load_gensim_model function which takes in a root path to search for the data and model. If it finds the model it loads it, otherwise, it reads the data, trains the model, saves the model and returns the model. You can read the code in my utils.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "model = load_gensim_model(os.getcwd()+\"/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since gensim only allows for word2vec, I need to make a module that can read a string of words and return the average of all the vectors\n",
    "\n",
    "I then have another function that applies this sentence2vec function to an entire column of a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = 300\n",
    "\n",
    "def sentence2vec(words):\n",
    "    \"\"\"\n",
    "    Module that converts takes in a string \n",
    "    with multiple words, takes the word2vec\n",
    "    of each word, and then averages them all\n",
    "    to get a sentence to vec\n",
    "    \n",
    "    For this dataset, no tf-idf is needed\n",
    "    because no word appears twice in a single sentance\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_vec = np.array([\n",
    "                    np.mean([model.wv[w] for w in words.split() if w in model.wv]\n",
    "                            or [np.zeros(dim)], axis=0)\n",
    "                ]).reshape([300])\n",
    "    return avg_vec\n",
    "\n",
    "\n",
    "def get_vector_column(column_name, keys, df):\n",
    "    \n",
    "    vector_keys = []\n",
    "    \n",
    "    for key in keys:\n",
    "\n",
    "        vector_keys.append(sentence2vec(key))\n",
    "    \n",
    "    col = np.zeros( [df.shape[0], 300] )\n",
    "    \n",
    "    for i, key in enumerate(keys):\n",
    "        index = df[column_name] == key\n",
    "        \n",
    "        index = index.values.reshape([df.shape[0], 1])\n",
    "        \n",
    "        \n",
    "        index = np.repeat(index, 300, axis=1)\n",
    "        \n",
    "        np.place(col, index, vector_keys[i])\n",
    "        \n",
    "    return col\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Data Preparations\n",
    "\n",
    "Now, I want to prepare training data for a deep learning approach. My plan is to have 2 different models to train. 1 that only accepts the guaranteed information i.e. the department and the appropriation and tries to predict the expense type. Another that takes in the department, appropriation and the sentence vector describing the department. I have 2 functions below used to build up the corresponding datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    \n",
    "def one_hot_Y(Y):\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(Y)\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    \n",
    "    return onehot_encoded, label_encoder\n",
    "    \n",
    "def build_train_set(df, columns):\n",
    "    \n",
    "    #name_vectors = get_vector_column(\"Program_Name\", programs, df)\n",
    "    \n",
    "    X_data = df[columns].values\n",
    "    \n",
    "    Y = df[\"Expense_Type\"].values\n",
    "    \n",
    "    Y, decoder = one_hot_Y(Y)\n",
    "    \n",
    "    return name_vectors, X_data, Y, decoder\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Set up the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Concatenate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Slow\n",
    "\n",
    "First I'm going to start out with a basic model that only accepts the guaranteed information. This will provide a good baseline for future models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_model = Sequential()\n",
    "\n",
    "in_shape = (2,)\n",
    "\n",
    "basic_model.add(Dense(128, input_shape=in_shape, activation='relu' ))\n",
    "basic_model.add(Dense(256, activation='relu'))\n",
    "basic_model.add(Dense(len(expenses), activation='softmax'))\n",
    "\n",
    "basic_model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14243/14243 [==============================] - 1s 58us/step - loss: 1.1243 - acc: 0.5463\n",
      "Epoch 2/10\n",
      "14243/14243 [==============================] - 1s 56us/step - loss: 1.1367 - acc: 0.5478\n",
      "Epoch 3/10\n",
      "14243/14243 [==============================] - 1s 56us/step - loss: 1.1135 - acc: 0.5393\n",
      "Epoch 4/10\n",
      "14243/14243 [==============================] - 1s 56us/step - loss: 1.1139 - acc: 0.5403\n",
      "Epoch 5/10\n",
      "14243/14243 [==============================] - 1s 57us/step - loss: 1.0466 - acc: 0.5469\n",
      "Epoch 6/10\n",
      "14243/14243 [==============================] - 1s 56us/step - loss: 1.0984 - acc: 0.5486\n",
      "Epoch 7/10\n",
      "14243/14243 [==============================] - 1s 57us/step - loss: 1.0888 - acc: 0.5403\n",
      "Epoch 8/10\n",
      "14243/14243 [==============================] - 1s 58us/step - loss: 1.0974 - acc: 0.5527\n",
      "Epoch 9/10\n",
      "14243/14243 [==============================] - 1s 59us/step - loss: 1.2429 - acc: 0.5533\n",
      "Epoch 10/10\n",
      "14243/14243 [==============================] - 1s 57us/step - loss: 1.1169 - acc: 0.5375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6e1fccbe0>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_vectors, train_data, Y, decoder = build_train_set(full_data, guaranteed)\n",
    "\n",
    "basic_model.fit(train_data, Y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaway\n",
    "\n",
    "So unsurprisingly, the model can't even fit the training set much above 50%, much less a test set. I don't see much gain by hyper-parameter tinkering at this point. I think the route to take with the only guaranteed data filling in is just using the random forest. Now I'm gonna try out the non-guaranteed data sentance encoding to see if it helps much. I don't have great hopes, but it's worth a try :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_X = np.concatenate([train_data, name_vectors], axis=1)\n",
    "\n",
    "bigger_model = Sequential()\n",
    "\n",
    "in_shape = (302,)\n",
    "\n",
    "bigger_model.add(Dense(128, input_shape=in_shape, activation='relu' ))\n",
    "bigger_model.add(Dense(256, activation='relu'))\n",
    "bigger_model.add(Dense(len(expenses), activation='softmax'))\n",
    "\n",
    "bigger_model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14243/14243 [==============================] - 1s 82us/step - loss: 7.6928 - acc: 0.4939\n",
      "Epoch 2/10\n",
      "14243/14243 [==============================] - 1s 75us/step - loss: 7.5460 - acc: 0.4979\n",
      "Epoch 3/10\n",
      "14243/14243 [==============================] - 1s 76us/step - loss: 7.4784 - acc: 0.4974\n",
      "Epoch 4/10\n",
      "14243/14243 [==============================] - 1s 76us/step - loss: 7.3967 - acc: 0.5059\n",
      "Epoch 5/10\n",
      "14243/14243 [==============================] - 1s 75us/step - loss: 7.2776 - acc: 0.5022\n",
      "Epoch 6/10\n",
      "14243/14243 [==============================] - 1s 77us/step - loss: 6.9535 - acc: 0.5056\n",
      "Epoch 7/10\n",
      "14243/14243 [==============================] - 1s 78us/step - loss: 1.8774 - acc: 0.5119\n",
      "Epoch 8/10\n",
      "14243/14243 [==============================] - 1s 78us/step - loss: 1.5324 - acc: 0.5181\n",
      "Epoch 9/10\n",
      "14243/14243 [==============================] - 1s 77us/step - loss: 1.6682 - acc: 0.5278\n",
      "Epoch 10/10\n",
      "14243/14243 [==============================] - 1s 78us/step - loss: 1.2556 - acc: 0.5357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6d9f519e8>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger_model.fit(big_X, Y, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last DL Effort\n",
    "\n",
    "So the last few efforts didn't go very well, so I'm gonna try 1 more task. I'm gonna try to run the word encodings through a FC encoder, then concatenate that with the other data, and then make a prediction\n",
    "\n",
    "But, given the small sample size and wide variety of uncorrelated inputs, I didn't think this was a problem well suited for deep learning. I was more interested in whether the vectorization of the sentences would show any improvements over the baseline but it did not seem to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = Input(shape=(300,))\n",
    "\n",
    "enc1 = Dense(128, activation='relu')(vec)\n",
    "enc2 = Dense(64, activation='relu')(enc1)\n",
    "enc3 = Dense(5, activation='relu')(enc2)\n",
    "\n",
    "data = Input(shape=(2,))\n",
    "\n",
    "full_data = Concatenate()([vec, data])\n",
    "\n",
    "fc1 = Dense(64, activation='relu')(full_data)\n",
    "fc2 = Dense(128, activation='relu')(fc1)\n",
    "output = Dense(len(expenses), activation='softmax')(fc2)\n",
    "\n",
    "final_model = Model([vec, data], output)\n",
    "\n",
    "final_model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14243/14243 [==============================] - 1s 63us/step - loss: 7.7375 - acc: 0.4858\n",
      "Epoch 2/10\n",
      "14243/14243 [==============================] - 1s 52us/step - loss: 7.6900 - acc: 0.4934\n",
      "Epoch 3/10\n",
      "14243/14243 [==============================] - 1s 52us/step - loss: 7.5510 - acc: 0.4992\n",
      "Epoch 4/10\n",
      "14243/14243 [==============================] - 1s 53us/step - loss: 7.6876 - acc: 0.4944\n",
      "Epoch 5/10\n",
      "14243/14243 [==============================] - 1s 54us/step - loss: 7.6477 - acc: 0.4936\n",
      "Epoch 6/10\n",
      "14243/14243 [==============================] - 1s 54us/step - loss: 7.4674 - acc: 0.5035\n",
      "Epoch 7/10\n",
      "14243/14243 [==============================] - 1s 55us/step - loss: 7.4139 - acc: 0.4976\n",
      "Epoch 8/10\n",
      "14243/14243 [==============================] - 1s 55us/step - loss: 7.0525 - acc: 0.5082\n",
      "Epoch 9/10\n",
      "14243/14243 [==============================] - 1s 57us/step - loss: 2.9391 - acc: 0.5119\n",
      "Epoch 10/10\n",
      "14243/14243 [==============================] - 1s 58us/step - loss: 1.2222 - acc: 0.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6cd462390>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit([name_vectors, train_data], Y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done with the Dirty Digging\n",
    "\n",
    "I'm going to now move my stuff over to a clean notebook and try to work through some final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
